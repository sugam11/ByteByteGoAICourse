{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0fb30d",
   "metadata": {},
   "source": [
    "# Project 4: **Build a Deep Research System**\n",
    "Welcome to project 4! For this project, we shift our focus from tool use and agents to *reasoning* models. You will practice state‑of‑the‑art inference‑time scaling methods such as *Chain‑of‑Thought* prompting and *Tree‑of‑Thoughts*, and briefly explore high-levels of training reasoning models using techniques like **STaR**.\n",
    "\n",
    "\n",
    "Finally, you will put everything together to build a *deep research agent* that can browse the web, reason over what it finds, and give structured answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54845369",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* Apply common inference‑time scaling methods: **zero‑shot / few‑shot CoT, self‑consistency, sequential decoding, tree‑of‑thoughts**  \n",
    "* Gain intuition for **training** reasoning‑capable models following **STaR** approach \n",
    "* Build a minimal **deep‑research agent** that combines step‑by‑step reasoning with live web search   \n",
    "* Practice extending deep-search to a multi-agent system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a40a86",
   "metadata": {},
   "source": [
    "## Roadmap  \n",
    "1. Environment setup  \n",
    "2. Inference‑time scaling  \n",
    "   2.1 Few‑shot & zero‑shot CoT  \n",
    "   2.2 Self‑consistency\n",
    "   2.3 Sequential revisions  \n",
    "   2.4 Tree‑of‑Thought\n",
    "3. STaR for training models for reasoning  \n",
    "4. Deep-research agent  \n",
    "5. (Optional) Multi-agent deep-research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e480f76",
   "metadata": {},
   "source": [
    "# 1‑ Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2218",
   "metadata": {},
   "source": [
    "## 1.1- Conda environment\n",
    "\n",
    "Before we start coding, you need a reproducible setup. Open a terminal in the same directory as this notebook and run:\n",
    "\n",
    "```bash\n",
    "# Create and activate the conda environment\n",
    "conda env create -f environment.yaml && conda activate deep_research\n",
    "\n",
    "# Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=deep_research --display-name \"deep_research\"\n",
    "```\n",
    "Once this is done, you can select \"deep_research\" from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "## 1.2 Ollama setup\n",
    "\n",
    "In this project we use the `llama3.2:3b` and `deepseek-r1:8b` models. You can try other smaller or larger reasoning LLMs such as `qwen2.5:3b-instruct` or `phi4-mini` to compare performance. Explore available models here: https://ollama.com/library.\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "ollama pull deepseek-r1:8b\n",
    "# Additional small reasoning models to compare\n",
    "# ollama pull qwen2.5:3b-instruct\n",
    "# ollama pull phi4-mini\n",
    "\n",
    "```\n",
    "\n",
    "`ollama pull` downloads the model so you can run it locally without API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8d1b7",
   "metadata": {},
   "source": [
    "---  \n",
    "# 2‑ Inference‑time scaling\n",
    "\n",
    "Inference-time scaling refers to techniques that make an existing model reason better without retraining it. Instead of changing the model’s weights, we achieve reasoning capability by adjusting how we prompt, sample, or aggregate LLM's outputs.\n",
    "\n",
    "In this section, we’ll explore several inference-time strategies that improve reasoning quality using a non-reasoning base model. You will experiment with and compare methods such as:\n",
    "\n",
    "- Few-shot Chain-of-Thought (CoT)\n",
    "- Zero-shot CoT\n",
    "- Self-consistency\n",
    "- Sequential revision\n",
    "- Tree-of-Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d499a",
   "metadata": {},
   "source": [
    "### 2.1: Few‑Shot CoT\n",
    "Few-shot prompting helps a model reason by showing one or multiple examples before asking a new question. By observing the pattern of reasoning and final answers, the model learns how to structure its own reasoning process on the new input.\n",
    "\n",
    "In this exercise, you will create a prompt that includes a few example Q&A pairs demonstrating step-by-step reasoning. Then, you will feed a new question and see the model’s output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we can use the formula for the perimeter of a rectangle:\n",
      "\n",
      "Perimeter = 2(length + width)\n",
      "\n",
      "Since we know the perimeter (40 cm) and the width (5 cm), we can plug in these values and solve for the length:\n",
      "\n",
      "40 = 2(length + 5)\n",
      "20 = length + 5\n",
      "length = 15\n",
      "\n",
      "The final answer is: 15 cm\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Write a few examples showing reasoning steps\n",
    "# Step 2: Write your new question\n",
    "# Step 3: Concatenate examples + new question into a single prompt\n",
    "# Step 4: Call your Ollama or OpenAI client to get a response from llama3.2:3b # e.g., client.chat.completions.create(...)\n",
    "# Step 5: Print the final answer\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "\n",
    "few_shot_examples = \"\"\"Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
    "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
    "\n",
    "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
    "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
    "\"\"\"\n",
    "\n",
    "question = \"A rectangle has perimeter 40 cm and width 5 cm. What is its length?\"\n",
    "prompt = few_shot_examples + f\"Q: {question} A:\"\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "    temperature=0.9\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e29d9",
   "metadata": {},
   "source": [
    "### (Optional) Few-shot CoT on GPT2\n",
    "GPT-2 is a pre-trained language model without instruction tuning. It continues text rather than answering questions. In this section, you'll try the exact same CoT pattern on GPT-2 and observe what happens. The goal is to test whether few-shot CoT alone can elicit structured reasoning from a non-chat LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy decoding:\n",
      " Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
      "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5\n",
      "\n",
      "Sampled decoding:\n",
      " Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
      "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "A: Rectangles have the same diameter as the outside of them. It is 40 cm.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "\n",
      "A: Net fill = 5-3 = 2 L/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load GPT-2 text-generation from huggingface (https://huggingface.co/docs/transformers/en/model_doc/gpt2)\n",
    "# Step 2: Write 1–2 few-shot reasoning examples (short, explicit steps + final answer in your own unique format)\n",
    "# Step 3: Append a new test question after the examples to form one prompt string\n",
    "# Step 4: Generate 1–3 completions with different decoding settings (e.g., greedy vs. top-k)\n",
    "# Step 5: Print raw outputs; check if steps are followed and if the final answer is correct\n",
    "\n",
    "# MPS stuff\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "assert torch.backends.mps.is_available(), \"MPS not available on this system\"\n",
    "torch.mps.empty_cache()\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "\n",
    "pipeline = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\", dtype=torch.float16, device=device)\n",
    "\n",
    "few_shot = \"\"\"Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
    "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
    "\n",
    "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
    "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
    "\"\"\"\n",
    "\n",
    "q = \"A rectangle has perimeter 40 cm and width 5 cm. What is its length?\"\n",
    "prompt = few_shot + f\"Q: {q}\\nA:\"\n",
    "\n",
    "# # Greedy\n",
    "out_greedy = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    "    use_cache=False\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "out_sample = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    temperature=0.8,\n",
    "    use_cache=False\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "print(\"Greedy decoding:\\n\", out_greedy)\n",
    "print(\"\\nSampled decoding:\\n\", out_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adee0e7",
   "metadata": {},
   "source": [
    "### 2.2: Zero‑Shot Chain‑of‑Thought\n",
    "Zero-shot CoT encourages the model to reason without examples by adding a short cue such as “Let’s think step by step.” This simple phrase often activates the model’s latent reasoning ability even when no demonstrations are provided. It serves as a baseline to compare with few-shot and other inference-time scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c444eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To understand why neural networks are used to build Large Language Models (LLMs), let's break down the process step by step:\n",
      "\n",
      "1. **Understanding the Problem**: The primary goal of building an LLM is to create a model that can generate human-like text, answer questions, or perform other natural language processing tasks.\n",
      "\n",
      "2. **Traditional Approaches**: Before neural networks, traditional approaches to NLP involved rule-based systems and statistical models. These methods were limited in their ability to handle complex linguistic structures and nuances of human language.\n",
      "\n",
      "3. **The Rise of Neural Networks**: In the 1980s and 1990s, researchers began exploring the use of neural networks for NLP tasks. The key innovation was the development of recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, which allowed models to capture sequential dependencies in language.\n",
      "\n",
      "4. **Why Neural Networks?**: Neural networks are particularly well-suited for LLMs because they can:\n",
      "   - Learn complex patterns in language data\n",
      "   - Handle sequential dependencies between words or tokens\n",
      "   - Capture contextual relationships and nuances of human language\n",
      "\n",
      "5. **Key Architectures**: The most common architectures used in LLMs are:\n",
      "   - Recurrent Neural Networks (RNNs)\n",
      "   - Long Short-Term Memory (LSTM) networks\n",
      "   - Transformers, which have become the de facto standard for modern LLMs\n",
      "\n",
      "6. **Why Transformers?**: Transformers revolutionized the field of NLP by introducing self-attention mechanisms, which allow models to weigh the importance of different tokens in a sentence relative to each other. This leads to better performance and more efficient training.\n",
      "\n",
      "7. **Training Large Models**: The availability of large amounts of labeled data (e.g., text corpora) has enabled researchers to train massive neural networks that can capture complex patterns in language. These models are often trained using techniques like masked language modeling, next sentence prediction, or other supervised learning objectives.\n",
      "\n",
      "8. **Advantages of Neural Networks**: The use of neural networks for LLMs offers several advantages:\n",
      "   - Ability to learn from large amounts of data\n",
      "   - Flexibility and adaptability in handling different linguistic tasks\n",
      "   - Potential for significant improvements over traditional NLP approaches\n",
      "\n",
      "In summary, the use of neural networks for building LLMs is driven by their ability to capture complex patterns in language, handle sequential dependencies, and learn from large amounts of data. The development of architectures like RNNs, LSTMs, and transformers has enabled researchers to create models that can generate human-like text or perform other NLP tasks with high accuracy.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Write the question and a zero-shot CoT cue (e.g., \"Let's think step by step.\")\n",
    "# Step 2: Build a single prompt string that includes brief role guidance plus the question\n",
    "# Step 3: Call your Ollama or OpenAI client to get a response from llama3.2:3b  # e.g., client.chat.completions.create(...)\n",
    "# Step 4: Print the chain and the final answer\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "\n",
    "question = \"Why do we use neural network to build LLMs?\"\n",
    "\n",
    "prompt = f\"\"\"You are a knowledgeable tutor. Answer the question. \n",
    "Question: {question}\n",
    "Let's think step by step.\"\"\"\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686708da",
   "metadata": {},
   "source": [
    "### 2.3 Self‑Consistency\n",
    "Self-consistency enhances reasoning accuracy by sampling multiple independent reasoning paths for the same question instead of relying on a single deterministic answer. Each run may follow a slightly different logical chain, and the diversity helps correct individual mistakes. After generating several reasoning traces, you then aggregate the final answers using majority voting.\n",
    "\n",
    "This approach is especially useful when tasks involve multi-step reasoning or arithmetic, where single-path outputs may be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fb325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votes: Counter({'12 is a possible candidate for being the square root of 144.': 1, '**the square root of 144 is 12**.': 1, '**The square root of 144 is 12.**': 1, '**': 1, 'instead of using trial and error division, we can simply state the square root of 144 as 12.': 1})\n",
      "Chosen answer: 12 is a possible candidate for being the square root of 144.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re, collections\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "\n",
    "def cot_answer(question, temperature=1.3):\n",
    "    prompt = f\"\"\"Answer the following question with step-by-step reasoning and final answer after **Therefore,**.\n",
    "        Question: {question}\n",
    "        Let's think step by step.\"\"\"\n",
    "    \n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    content = r.choices[0].message.content\n",
    "    match = re.search(r\"[Tt]herefore,?\\s*(.*)\", content) # extract text after 'Therefore'.\n",
    "    return content, match.group(1).strip() if match else None\n",
    "\n",
    "\n",
    "def self_consistent(question, n=5):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        _, ans = cot_answer(question, temperature=0.9)\n",
    "        answers.append(ans)\n",
    "    counter = collections.Counter(answers)\n",
    "    winner, _ = counter.most_common(1)[0]\n",
    "    return winner, counter\n",
    "\n",
    "\n",
    "question = \"What is the square root of 144?\"\n",
    "winner, counter = self_consistent(question)\n",
    "print(\"Votes:\", counter)\n",
    "print(\"Chosen answer:\", winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bea715",
   "metadata": {},
   "source": [
    "### 2.4: Sequential Revision\n",
    "\n",
    "Sequential revision iteratively improves an answer by generating a first draft, critiquing it, and producing revised drafts that condition on prior answers. Each round should be short and focused, so improvements accumulate without drifting from the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft 1: Let's break this down step by step:\n",
      "\n",
      "1. Let's call the width \"w\" (in cm).\n",
      "2. Since the rectangle is twice as long as it is wide, the length can be represented as 2w.\n",
      "3. The perimeter of a rectangle is given by the formula: Perimeter = 2(length + width)\n",
      "4. We are told that the perimeter is 30 cm, so we can set up an equation: \n",
      "   30 = 2(2w + w)\n",
      "5. Simplify the equation:\n",
      "   30 = 6w\n",
      "6. Divide both sides by 6 to solve for w:\n",
      "   w = 30/6\n",
      "   w = 5\n",
      "\n",
      "This means the width is 5 cm.\n",
      "\n",
      "7. Since the length is twice the width, we can now find the length: \n",
      "   Length = 2w\n",
      "   Length = 2(5)\n",
      "   Length = 10 cm\n",
      "\n",
      "8. Now that we have both dimensions (width and length), we can calculate the area:\n",
      "   Area = length × width\n",
      "   Area = 10 × 5\n",
      "   Area = 50\n",
      "Draft 2: The area of the rectangle is 50 square centimeters (cm²). To find this, we first calculated that the width was 5 cm and the length was twice the width, so 10 cm. Then, using these dimensions, we multiplied them together to get the area.\n",
      "Draft 3: The perimeter of a rectangle is given by the formula P = 2L + 2W, where L is the length and W is the width. We are told that the rectangle is twice as long as it is wide (L = 2W), so we can substitute this into the perimeter equation to get 30 = 2(2W) + 2W.\n",
      "\n",
      "Simplifying this equation gives us 30 = 4W + 2W, which simplifies further to 30 = 6W. Solving for W by dividing both sides by 6, we find that the width is 5 cm.\n",
      "\n",
      "Since the length is twice the width (L = 2W), the length is 10 cm.\n",
      "\n",
      "To find the area of a rectangle, we multiply its length and width together: Area = L × W. Therefore, the area of this rectangle is 5 cm × 10 cm = 50 square centimeters (cm²).\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "\n",
    "def sequential_revision(question: str, max_steps: int = 3) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Keep your answers clear and correct.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "   \n",
    "    draft = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "    ).choices[0].message.content.strip()\n",
    "    print(f\"Draft 1: {draft}\")\n",
    "\n",
    "    # Iterative revision\n",
    "    for idx in range(1, max_steps):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Improve answers by making them clearer and more accurate.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": draft},\n",
    "            {\"role\": \"user\", \"content\": \"Please revise your answer. Make it clearer, more accurate, and better written. Only include the new answer.\"}\n",
    "        ]\n",
    "        draft = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "        ).choices[0].message.content.strip()\n",
    "        print(f\"Draft {idx+1}: {draft}\")\n",
    "\n",
    "    return draft\n",
    "\n",
    "\n",
    "output = sequential_revision(\"If a rectangle is twice as long as it is wide and the perimeter is 30 cm, what is the area?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9319ee8",
   "metadata": {},
   "source": [
    "### 2.5 Tree‑of‑Thoughts\n",
    "Tree-of-Thoughts reframes reasoning as a search process rather than a single forward chain.\n",
    "Instead of producing one linear sequence of thoughts, the model generates multiple candidate thoughts at each step, evaluates their promise, and then expands only the best few. This allows exploration of different reasoning paths before committing to a final answer, similar to how humans brainstorm, prune, and refine ideas.\n",
    "\n",
    "\n",
    "In this section, you’ll experiment with two simplified versions of ToT:\n",
    "1. Word Ladder puzzle solver: a small example where each “thought” is a candidate word transition.\n",
    "2. Generic ToT search (depth 2, width 2): a minimal logic to expand, evaluate, and select reasoning branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d047801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['hit', 'hot', 'dot', 'dog', 'cog']\n"
     ]
    }
   ],
   "source": [
    "###### Word Ladder Puzzle ##########\n",
    "\n",
    "def neighbors(word, vocabulary):\n",
    "    for i, c1 in enumerate(word):\n",
    "        for c2 in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            if c1 != c2:\n",
    "                candidate = word[:i] + c2 + word[i+1:]\n",
    "                if candidate in vocabulary:\n",
    "                    yield candidate\n",
    "\n",
    "\n",
    "def tree_of_thought(start, goal, vocab, max_depth=5, beam_width=4):\n",
    "    frontier = [[start]]\n",
    "    for depth in range(max_depth):\n",
    "        candidates = []\n",
    "        for path in frontier:\n",
    "            for nxt in neighbors(path[-1], vocab):\n",
    "                if nxt in path:  # avoid loops\n",
    "                    continue\n",
    "                candidates.append(path + [nxt])\n",
    "        # score: negative edit distance to goal\n",
    "        scored = sorted(candidates, key=lambda p: sum(a!=b for a,b in zip(p[-1], goal)))\n",
    "        frontier = scored[:beam_width]\n",
    "        if any(p[-1] == goal for p in frontier):\n",
    "            return [p for p in frontier if p[-1]==goal][0]\n",
    "    return None\n",
    "\n",
    "\n",
    "vocab = {\"hit\",\"dot\",\"cog\",\"log\",\"dog\",\"lot\",\"lit\",\"hot\"}\n",
    "print(tree_of_thought(\"hit\", \"cog\", vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89067302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution (score 8):\n",
      "Here are two potential next steps to develop the plan for the weekend science workshop:\n",
      "\n",
      "1. **Define the Workshop's Theme and Objectives**: Determine what specific scientific topics or themes would be most engaging and accessible for 12-year-olds. This could include topics such as:\n",
      "\t* Environmental science (e.g., recycling, climate change)\n",
      "\t* Simple physics (e.g., magnets, solar system)\n",
      "\t* Biology (e.g., cells, genetics)\n",
      "\n",
      "Establishing a clear theme and set of objectives will help guide the planning process and ensure that the workshop stays focused and interactive.\n",
      "\n",
      "2. **Identify Potential Facilitators or Guest Speakers**: Consider engaging experienced science educators, scientists, or industry experts to lead hands-on activities, discussions, and experiments during the workshop. This could include:\n",
      "\t* Local science teachers or professors\n",
      "\t* Museum staff or curators\n",
      "\t* Scientists from relevant industries (e.g., environmental consulting, biotechnology)\n",
      "\n",
      "Involving knowledgeable facilitators will enhance the workshop's credibility, authenticity, and engagement, providing a more enriching experience for participants.\n",
      "\n",
      "These next steps will help build on the current partial solution by clarifying the workshop's goals and securing expertise to deliver engaging science experiences.\n",
      "Here are two potential next steps to further develop the plan for the weekend science workshop:\n",
      "\n",
      "1. **Develop an Interactive and Immersive Learning Environment**: Create a hands-on, inquiry-based learning environment that encourages active participation, collaboration, and creativity among participants. Consider incorporating activities such as:\n",
      "\t* Laboratory-style experiments with real-world applications\n",
      "\t* Mind mapping, brainstorming, and problem-solving exercises\n",
      "\t* Collaborative projects or hackathons related to the chosen theme\n",
      "\t* Virtual reality (VR) or augmented reality (AR) experiences\n",
      "\n",
      "Having an immersive learning environment will engage participants more thoroughly and foster a deeper understanding of scientific concepts.\n",
      "\n",
      "2. **Design a Comprehensive Program Schedule**: Create a detailed program schedule that outlines the workshop's structure, pace, and activities. This could include:\n",
      "\t* A morning orientation session to discuss the theme, objectives, and expectations\n",
      "\t* A series of hands-on workshops or experiments during the afternoon\n",
      "\t* Breakout sessions for collaboration, discussion, and Q&A\n",
      "\t* An evening activity or game that reinforces learning and encourages reflection\n",
      "\n",
      "A well-structured program schedule will ensure a smooth flow of activities, manage time effectively, and meet the needs of varied learners.\n",
      "\n",
      "Both of these next steps will further enhance the overall plan by focusing on the interactive nature of science education and creating a structured program to support participant engagement.\n"
     ]
    }
   ],
   "source": [
    "###### Generic ToT Search ##########\n",
    "\n",
    "import re\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def propose_thoughts(question, state, k=2):\n",
    "    prompt = f\"\"\"You are exploring solutions.\n",
    "            Problem: {question}\n",
    "            Current partial solution: {state}\n",
    "\n",
    "            Propose at most {k} different next thoughts.\"\"\"\n",
    "    \n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.9,\n",
    "        n=k\n",
    "    )\n",
    "    return [c.message.content.strip() for c in r.choices]\n",
    "\n",
    "\n",
    "def score_state(question, state):\n",
    "    prompt = f\"\"\"Problem: {question}\n",
    "        Rate from 1-10 how promising this partial solution is: {state}\"\"\"\n",
    "    \n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    try:\n",
    "        return int(re.findall(r\"\\d+\", r.choices[0].message.content)[0])\n",
    "    except Exception:\n",
    "        return 5  # neutral fallback\n",
    "\n",
    "\n",
    "def tree_of_thoughts(question, depth=2, width=2):\n",
    "    frontier = [(\"\", 0)]\n",
    "    for _ in range(depth):\n",
    "        new_frontier = []\n",
    "        for state, _ in frontier:\n",
    "            for thought in propose_thoughts(question, state, k=width):\n",
    "                new_state = (state + \"\\n\" + thought).strip()\n",
    "                score = score_state(question, new_state)\n",
    "                new_frontier.append((new_state, score))\n",
    "        new_frontier.sort(key=lambda x: x[1], reverse=True)  # keep top‑k\n",
    "        frontier = new_frontier[:width]\n",
    "    best_state, best_score = frontier[0]\n",
    "    return best_state, best_score\n",
    "\n",
    "\n",
    "question = \"Design a plan for a weekend science workshop for 12-year-olds.\"\n",
    "solution, score = tree_of_thoughts(question)\n",
    "\n",
    "print(f\"Best solution (score {score}):\\n{solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc38f6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 3‑ Training Models for Reasoning\n",
    "\n",
    "### 3.1: CoT Training\n",
    "Chain-of-Thought (CoT) training conditions the model on explicit rationales during fine-tuning. Instead of teaching the model to output only the final answer, we train on (question, rationale, answer) so the model learns to internalize multi-step reasoning patterns. A practical recipe is STaR (Self-Taught Reasoner), which uses a stronger teacher model to bootstrap rationales that a smaller student can learn from.\n",
    "\n",
    "For tasks that require multi-hop reasoning, models fine-tuned on rationales often achieve higher accuracy and are more stable at inference time than models trained on direct answers only. \n",
    "\n",
    "Training a full language model is beyond the scope of this notebook, but here is the high-level workflow followed by a short pseudocode:\n",
    "- Collect questions: Prepare a dataset of questions and correct answers.\n",
    "- Generate rationales: Use a strong LLM to produce step-by-step reasoning ending with the correct answer.\n",
    "- Filter and clean: Discard incorrect or low-quality rationales.\n",
    "- Prepare training data: Format triples (question, rationale, answer) for supervised fine-tuning.\n",
    "- Fine-tune: Fine-tune the LLM on rationales.\n",
    "- Iterate: Refine prompts, improve data quality, and retrain for stronger reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (STaR loop)\n",
    "# for round in 1 ... iters:\n",
    "    # STEP 1: self-generate reasoning (teacher creates rationale + answer)\n",
    "    # STEP 2: keep only correct, high-quality traces\n",
    "    # STEP 3: fine-tune student on (question, rationale, answer) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b53c70",
   "metadata": {},
   "source": [
    "### 3.2: ORM vs PRM + RL\n",
    "Training a Reward Model (RM) allows large language models to be improved through reinforcement learning (RL). Instead of fine-tuning directly on examples, we train a separate model that can score or rank model outputs, and use those scores as feedback signals to refine the policy model.\n",
    "\n",
    "Two main reward modeling approaches are ORM (predicts a scalar reward for the final answer) and PRM (evaluates the reasoning steps instead of just the outcome)\n",
    "\n",
    "\n",
    "\n",
    "| Approach | Typical loss | When to use |\n",
    "|-----------|-------------|-------------|\n",
    "|*Outcome Reward Model* | Predict scalar reward | Easy to collect training data using verifiers |\n",
    "|*Process Reward Model* | Predict rewards per step | Difficult to collect training data but more accurate |\n",
    "| *RLHF* | Use RM as reward in **RL** fine‑tuning | Aligns policy with human signals | Aligns model policy with human or synthetic preferences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for round = 1 ... iters:\n",
    "    # STEP 1:  Generate reasoning\n",
    "        # sample a minibatch of questions\n",
    "        # policy roll‑out (actions + log‑probs)\n",
    "    # STEP 2:  Score the trajectory\n",
    "        # ORM: scalar reward for the final answer / PRM: scalar reward for the thought process\n",
    "    # STEP 3:  Reinforce the policy (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a81a6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 4‑ A Deep Research Agent\n",
    "\n",
    "A deep-research agent pairs a reasoning model (e.g., deepseek-r1) with external tools for web search and retrieval. We will follow the ReAct pattern: the model writes short thoughts, decides when to call tools, reads observations, and continues reasoning until it can answer or reaches a step limit.\n",
    "\n",
    "We now combine a **search tool** with a reasoning model (e.g., `deepseek-r1`) in a multi-step setup. We follow the *ReAct* pattern (reason → tool → observation):\n",
    "\n",
    "1. The model reasoins and decides to use tools\n",
    "2. The agent searches and feed condensed snippets back as context\n",
    "3. Iterate until the model answers or hits a step limit\n",
    "\n",
    "We use `AgentType.OPENAI_FUNCTIONS`, which hides the loop inside the LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from langchain.tools import Tool\n",
    "\n",
    "\n",
    "def ddg_search(query: str, k: int = 5) -> str:\n",
    "    \"\"\"Basic DuckDuckGo web search that returns a concatenated text snippet.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [hit[\"body\"] for hit in ddgs.text(query, max_results=k)]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=ddg_search,\n",
    "    description=\"Search the public web. Input: a plain English query. Returns: concatenated snippets.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, user is asking about the best resources to learn machine learning for 2025. That's an interesting timeframe - they're looking ahead two years, which suggests they want future-proof knowledge rather than just current trends. \n",
      "\n",
      "First, I should acknowledge that predicting exact educational needs two years in advance is tricky because ML evolves rapidly. But some foundational concepts and practical skills will likely remain relevant regardless of technological shifts. The user probably wants to know what's most valuable now but with an eye toward long-term career sustainability.\n",
      "\n",
      "Hmm... they didn't specify their background or goals, which makes this broad. Are they a complete beginner? A developer looking to pivot? Or someone with math/stats knowledge wanting hands-on skills? Since they didn't say, I should cover multiple learning paths comprehensively.\n",
      "\n",
      "I notice they're asking about \"resources\" plural - not just courses but books, documentation, communities etc. That's good because ML mastery requires diverse materials. The mention of 2025 might imply interest in emerging tools like multimodal models or federated learning, though I shouldn't assume that yet.\n",
      "\n",
      "The user seems to be at an early stage of their ML journey - they're asking about starting points rather than advanced techniques. They probably want structured recommendations with clear progression paths. Since they didn't mention budget constraints, I can include both free and paid options.\n",
      "\n",
      "I should emphasize the importance of coding practice since ML is hands-on. The user might be tempted by passive learning but won't become proficient without implementation. Also need to stress that theoretical understanding goes hand-in-hand with practical application.\n",
      "\n",
      "For 2025 specifically, I'll highlight platforms showing staying power (like Google's MLCC) and mention how skills like prompt engineering might still be relevant despite tool changes - the underlying concepts persist even if interfaces evolve.\n",
      "</think>\n",
      "Okay, let's break down learning resources for Machine Learning in a way that positions you well for 2025. Keep in mind that while specific courses or tools may change slightly year-to-year, foundational knowledge and strong practical skills remain crucial.\n",
      "\n",
      "Here are some of the best types of resources categorized by need:\n",
      "\n",
      "## Foundational Knowledge & Theory\n",
      "\n",
      "1.  **Introductory Books:**\n",
      "    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for beginners, covers core concepts, algorithms (linear models, trees, SVMs), deep learning basics, and practical implementation using popular Python libraries. It's updated regularly.\n",
      "    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** More theoretical depth, good if you prefer a rigorous mathematical foundation or want to understand the underlying principles deeply.\n",
      "    *   **\"The Elements of Statistical Learning: Data Mining, Inference, and Prediction\" (2nd Edition):** The bible for statistical learning theory. Requires more math but provides deep insights into algorithms like SVMs, Boosting, Bagging, etc.\n",
      "\n",
      "## Practical Skills & Application\n",
      "\n",
      "1.  **Online Courses (Beginner to Advanced):**\n",
      "    *   **Coursera - \"Machine Learning\" by Andrew Ng:** Still one of the most popular and highly regarded introductions. Covers linear regression, logistic regression, neural networks, basic Python/ML concepts.\n",
      "    *   **Fast.ai:** Focuses on a top-down approach, teaching you to build models quickly using modern libraries (PyTorch). Great for developing practical intuition fast. Their curriculum is designed by practitioners for practitioners and evolves rapidly.\n",
      "    *   **DeepLearning.AI (formerly deeplearning.net):** Created by Andrew Ng's team, specifically targeting deep learning mastery after the foundational course. Highly structured and in-depth.\n",
      "    *   **Google MLCC (Machine Learning Crash Course):** Focuses heavily on TensorFlow and practical application using real-world datasets. Excellent for understanding core concepts through hands-on labs.\n",
      "\n",
      "2.  **Python Libraries & Documentation:**\n",
      "    *   **Scikit-Learn:** The go-to library for traditional machine learning in Python. Its documentation is comprehensive, well-structured, and includes examples (essential resource).\n",
      "    *   **TensorFlow:** Developed by Google, the primary framework for deep learning. Extensive tutorials, guides, and code samples.\n",
      "    *   **PyTorch:** Developed by Facebook (Meta), extremely popular for deep learning research and applications. Good documentation and tutorials available.\n",
      "\n",
      "## Deep Learning Focus\n",
      "\n",
      "1.  **Deep Learning Books:**\n",
      "    *   **\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville:** The comprehensive textbook covering the mathematical foundations and state-of-the-art techniques in depth.\n",
      "    *   **\"Deep Learning with PyT\n",
      "        \" Deep learning is a subfield of machine learning concerned with algorithms inspired by the structure and function of the brain, called artificial neural networks. It has been used successfully to solve complex problems in various domains such as computer vision, natural language processing, speech recognition, and game-playing.\n",
      "\n",
      "    Here are some top resources for deep learning:\n",
      "\n",
      "    *   **Deep Learning Specialization (Coursera) by Andrew Ng:** A highly recommended sequence of courses covering neural networks, backpropagation, various architectures (CNNs, RNNs), and applications. Requires commitment but is very effective.\n",
      "    *   **\"Deep Learning\" Book by Goodfellow et al.:** Available online for free. It's detailed and rigorous, suitable for those wanting deep theoretical understanding or self-study.\n",
      "\n",
      "## Coding & Implementation\n",
      "\n",
      "1.  **Kaggle:** More than just a platform for competitions, Kaggle is fantastic for learning through practice.\n",
      "    *   **Notebooks:** You can run code in their interactive environment, see working examples from other users/competitions.\n",
      "    *   **Datasets:** Access to real-world datasets.\n",
      "    *   **Kernel Leaderboard:** See what models top-performing users are building and how they implement them.\n",
      "\n",
      "## Specific Concepts & Advanced Topics\n",
      "\n",
      "1.  **YouTube Channels:**\n",
      "    *   **3Blue1Brown (Grant Sanderson):** Excellent for understanding the intuition behind complex ML/DL concepts through visually engaging videos.\n",
      "    *   **StatQuest with Josh Starne:** Focuses on explaining statistical and machine learning concepts very clearly and quickly, often using simple examples or visualizations. Great for grasping core ideas fast.\n",
      "\n",
      "2.  **Research Papers & Blogs:**\n",
      "    *   **arXiv.org:** A primary resource for accessing the latest research papers in ML/DL.\n",
      "    *   **Medium / Towards Data Science (Kaggle):** Curated content, tutorials, and explanations from practitioners covering various topics and trends.\n",
      "    *   **Machine Learning Blog by Jason Brownlee:** Provides a wealth of free resources, tutorials, and guides on specific ML techniques and tools.\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Python Dominance:** Python will likely remain the primary language for most ML/DL work in 2025. Focus your coding skills here.\n",
      "*   **TensorFlow vs PyTorch:** Both frameworks are widely used and evolving. Proficiency in at least one is essential, but learning concepts on one often translates to the other.\n",
      "*   **Cloud Platforms:** AWS, Azure, GCP offer ML services and courses that will be relevant as more companies move ML workloads to the cloud (likely still true in 2025).\n",
      "*   **Ethics & Responsible AI:** This is becoming increasingly important. Look for resources covering bias mitigation, fairness, accountability, etc.\n",
      "*   **Prompt Engineering:** While often associated with LLMs specifically, understanding how to effectively interact with models and structure prompts will remain a valuable skill even beyond large language models.\n",
      "\n",
      "## Recommendation\n",
      "\n",
      "Start with an introductory course or book (like Ng's ML course or Géron's book) to get the fundamentals. Then move towards more specialized areas using resources like Kaggle, specific courses on Coursera/DeepLearning.AI, and hands-on projects. Supplement this with visual explanations from channels like 3Blue1Brown.\n",
      "\n",
      "The best resource is often a combination: theory for understanding *why*, practice (coding) for *how*, and exposure to real-world applications (like on Kaggle). Good luck!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<think>\n",
      "Okay, user is asking about the best resources to learn machine learning for 2025. That's an interesting timeframe - they're looking ahead two years, which suggests they want future-proof knowledge rather than just current trends. \n",
      "\n",
      "First, I should acknowledge that predicting exact educational needs two years in advance is tricky because ML evolves rapidly. But some foundational concepts and practical skills will likely remain relevant regardless of technological shifts. The user probably wants to know what's most valuable now but with an eye toward long-term career sustainability.\n",
      "\n",
      "Hmm... they didn't specify their background or goals, which makes this broad. Are they a complete beginner? A developer looking to pivot? Or someone with math/stats knowledge wanting hands-on skills? Since they didn't say, I should cover multiple learning paths comprehensively.\n",
      "\n",
      "I notice they're asking about \"resources\" plural - not just courses but books, documentation, communities etc. That's good because ML mastery requires diverse materials. The mention of 2025 might imply interest in emerging tools like multimodal models or federated learning, though I shouldn't assume that yet.\n",
      "\n",
      "The user seems to be at an early stage of their ML journey - they're asking about starting points rather than advanced techniques. They probably want structured recommendations with clear progression paths. Since they didn't mention budget constraints, I can include both free and paid options.\n",
      "\n",
      "I should emphasize the importance of coding practice since ML is hands-on. The user might be tempted by passive learning but won't become proficient without implementation. Also need to stress that theoretical understanding goes hand-in-hand with practical application.\n",
      "\n",
      "For 2025 specifically, I'll highlight platforms showing staying power (like Google's MLCC) and mention how skills like prompt engineering might still be relevant despite tool changes - the underlying concepts persist even if interfaces evolve.\n",
      "</think>\n",
      "Okay, let's break down learning resources for Machine Learning in a way that positions you well for 2025. Keep in mind that while specific courses or tools may change slightly year-to-year, foundational knowledge and strong practical skills remain crucial.\n",
      "\n",
      "Here are some of the best types of resources categorized by need:\n",
      "\n",
      "## Foundational Knowledge & Theory\n",
      "\n",
      "1.  **Introductory Books:**\n",
      "    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for beginners, covers core concepts, algorithms (linear models, trees, SVMs), deep learning basics, and practical implementation using popular Python libraries. It's updated regularly.\n",
      "    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** More theoretical depth, good if you prefer a rigorous mathematical foundation or want to understand the underlying principles deeply.\n",
      "    *   **\"The Elements of Statistical Learning: Data Mining, Inference, and Prediction\" (2nd Edition):** The bible for statistical learning theory. Requires more math but provides deep insights into algorithms like SVMs, Boosting, Bagging, etc.\n",
      "\n",
      "## Practical Skills & Application\n",
      "\n",
      "1.  **Online Courses (Beginner to Advanced):**\n",
      "    *   **Coursera - \"Machine Learning\" by Andrew Ng:** Still one of the most popular and highly regarded introductions. Covers linear regression, logistic regression, neural networks, basic Python/ML concepts.\n",
      "    *   **Fast.ai:** Focuses on a top-down approach, teaching you to build models quickly using modern libraries (PyTorch). Great for developing practical intuition fast. Their curriculum is designed by practitioners for practitioners and evolves rapidly.\n",
      "    *   **DeepLearning.AI (formerly deeplearning.net):** Created by Andrew Ng's team, specifically targeting deep learning mastery after the foundational course. Highly structured and in-depth.\n",
      "    *   **Google MLCC (Machine Learning Crash Course):** Focuses heavily on TensorFlow and practical application using real-world datasets. Excellent for understanding core concepts through hands-on labs.\n",
      "\n",
      "2.  **Python Libraries & Documentation:**\n",
      "    *   **Scikit-Learn:** The go-to library for traditional machine learning in Python. Its documentation is comprehensive, well-structured, and includes examples (essential resource).\n",
      "    *   **TensorFlow:** Developed by Google, the primary framework for deep learning. Extensive tutorials, guides, and code samples.\n",
      "    *   **PyTorch:** Developed by Facebook (Meta), extremely popular for deep learning research and applications. Good documentation and tutorials available.\n",
      "\n",
      "## Deep Learning Focus\n",
      "\n",
      "1.  **Deep Learning Books:**\n",
      "    *   **\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville:** The comprehensive textbook covering the mathematical foundations and state-of-the-art techniques in depth.\n",
      "    *   **\"Deep Learning with PyT\n",
      "        \" Deep learning is a subfield of machine learning concerned with algorithms inspired by the structure and function of the brain, called artificial neural networks. It has been used successfully to solve complex problems in various domains such as computer vision, natural language processing, speech recognition, and game-playing.\n",
      "\n",
      "    Here are some top resources for deep learning:\n",
      "\n",
      "    *   **Deep Learning Specialization (Coursera) by Andrew Ng:** A highly recommended sequence of courses covering neural networks, backpropagation, various architectures (CNNs, RNNs), and applications. Requires commitment but is very effective.\n",
      "    *   **\"Deep Learning\" Book by Goodfellow et al.:** Available online for free. It's detailed and rigorous, suitable for those wanting deep theoretical understanding or self-study.\n",
      "\n",
      "## Coding & Implementation\n",
      "\n",
      "1.  **Kaggle:** More than just a platform for competitions, Kaggle is fantastic for learning through practice.\n",
      "    *   **Notebooks:** You can run code in their interactive environment, see working examples from other users/competitions.\n",
      "    *   **Datasets:** Access to real-world datasets.\n",
      "    *   **Kernel Leaderboard:** See what models top-performing users are building and how they implement them.\n",
      "\n",
      "## Specific Concepts & Advanced Topics\n",
      "\n",
      "1.  **YouTube Channels:**\n",
      "    *   **3Blue1Brown (Grant Sanderson):** Excellent for understanding the intuition behind complex ML/DL concepts through visually engaging videos.\n",
      "    *   **StatQuest with Josh Starne:** Focuses on explaining statistical and machine learning concepts very clearly and quickly, often using simple examples or visualizations. Great for grasping core ideas fast.\n",
      "\n",
      "2.  **Research Papers & Blogs:**\n",
      "    *   **arXiv.org:** A primary resource for accessing the latest research papers in ML/DL.\n",
      "    *   **Medium / Towards Data Science (Kaggle):** Curated content, tutorials, and explanations from practitioners covering various topics and trends.\n",
      "    *   **Machine Learning Blog by Jason Brownlee:** Provides a wealth of free resources, tutorials, and guides on specific ML techniques and tools.\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Python Dominance:** Python will likely remain the primary language for most ML/DL work in 2025. Focus your coding skills here.\n",
      "*   **TensorFlow vs PyTorch:** Both frameworks are widely used and evolving. Proficiency in at least one is essential, but learning concepts on one often translates to the other.\n",
      "*   **Cloud Platforms:** AWS, Azure, GCP offer ML services and courses that will be relevant as more companies move ML workloads to the cloud (likely still true in 2025).\n",
      "*   **Ethics & Responsible AI:** This is becoming increasingly important. Look for resources covering bias mitigation, fairness, accountability, etc.\n",
      "*   **Prompt Engineering:** While often associated with LLMs specifically, understanding how to effectively interact with models and structure prompts will remain a valuable skill even beyond large language models.\n",
      "\n",
      "## Recommendation\n",
      "\n",
      "Start with an introductory course or book (like Ng's ML course or Géron's book) to get the fundamentals. Then move towards more specialized areas using resources like Kaggle, specific courses on Coursera/DeepLearning.AI, and hands-on projects. Supplement this with visual explanations from channels like 3Blue1Brown.\n",
      "\n",
      "The best resource is often a combination: theory for understanding *why*, practice (coding) for *how*, and exposure to real-world applications (like on Kaggle). Good luck!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "MODEL = \"deepseek-r1:8b\"\n",
    "question = \"What are the best resources to learn machine learning in 2025?\"\n",
    "\n",
    "# Step 1: Initialize the reasoning model via ChatOllama\n",
    "llm = ChatOllama(model=MODEL, temperature=0.2)\n",
    "\n",
    "# Step 2: Build the agent with tool access (DuckDuckGo Search) and function-calling interface (initialize_agent)\n",
    "agent = initialize_agent(\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Step 3: Ask a query and let the agent search + reason to produce an answer\n",
    "result = agent.invoke({\"input\": question})\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1c3f7",
   "metadata": {},
   "source": [
    "# Optional (Multi-agent Deep Research)\n",
    "Instead of a single multi-step agent, you can design multiple collaborating agents such as a Planner, Searcher, Summarizer, and Verifier that pass information and refine each other’s outputs. This setup improves robustness, diversity of reasoning, and division of labor.\n",
    "\n",
    "Try building a simple setup with 2–3 agents that share goals and messages, for example Planner → Researcher → Writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59abf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_research(query, n=3):\n",
    "    # Run n independent research runs in parallel and return their answers.\n",
    "    # Steps: use ThreadPoolExecutor; submit n calls to your agent/search pipeline; gather results in order.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "answers = parallel_research(\"What are the best resources to learn ML in 2025?\")\n",
    "for i,a in enumerate(answers,1):\n",
    "    print(f\"[Run {i}] {a[:200]}…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507d0a4",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "* Practised various inference‑time reasoning methods\n",
    "* Gained intuition about training reasoning models\n",
    "* You have built a **deep-research agent**: reasoning model like deep-seek r1 + ReAct-style agent + tool use (web search)\n",
    "* Try adding more tools, and extending the deep-research to a multi-agent system: many agents researching web in parallel.\n",
    "\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The techniques you implemented here power many production agents and chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_research_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
